# Выбор технологии для поиска по базе фильмов

![image](https://pictures.s3.yandex.net/resources/S1.1_1_Search_1597772428.gif)

Когда возникает потребность найти фразу среди множества названий, первый вариант, который приходит в голову человеку, знакомому с SQL, — использовать оператор [LIKE](https://www.sqlitetutorial.net/sqlite-like/){target="_blank"}.

Если уверенный в своих планах на вечер пользователь введёт в поисковую строку запрос: `настоящий детектив`, сервис обратится к базе `select * from movies where name like '%настоящий детектив%'` и вернёт результат.

Большой плюс этого решения — быстрота реализации. Если в вашем проекте пользователи будут искать точные совпадения — номера ГОСТ-ов, описания OID-ов SNMP-протокола или марки стали — лишняя вариативность может только мешать.

Минус в том, что скорость поиска линейно зависит от объёма данных. В SQLite `LIKE` не использует индексы, а значит, чем больше в базе будет документов, тем дольше пользователь будет ждать ответ. А при смене порядка слов или опечатке список результатов будет пуст.

## Мини-квиз

У вас есть SQLite-база данных с фильмами. Сейчас поиск в сервисе работает через оператор `LIKE`. Он не всегда находит нужное, а при большой нагрузке начинает тормозить. Каким образом можно улучшить ситуацию?

* Написать код, исправляющий опечатки в запросах перед поиском в базе
    * ✅ Да, это [вполне возможно](https://norvig.com/spell-correct.html){target="_blank"}. 
* Написать код, разбивающий запрос на слова перед поиском по базе
    * ✅ Это тоже улучшит результаты. И в отличие от предыдущего варианта, это делается довольно быстро.
* Найти готовое решение, которое возьмёт поиск на себя
    * ✅ Лучший вариант! Прежде чем писать свои решения, обязательно изучите, как решают схожие проблемы другие разработчики. 
* Отказаться от SQLite и перенести данные в более шуструю базу
    * ✅ Почему бы и нет! SQLite — хорошая, но достаточно урезанная по возможностям база данных. Если рост нагрузки увеличится, её будет сложно масштабировать.    

Рассмотрим последние два варианта подробнее. Нужно решить, что будет выгоднее: модифицировать базу данных или использовать готовые решения? Каким способом лучше решить проблемы с отсутствием «умного» поиска и нестабильностью при нагрузке?

## Поиск по реляционным базам

Многие современные реляционные и NoSQL-базы данных поддерживают поиск по тексту. Это умеют SQLite ([FTS](https://www.sqlite.org/fts5.html){target="_blank"}), PostgreSQL ([to_tsvector](https://www.postgresql.org/docs/9.5/textsearch.html){target="_blank"}) и MySQL ([FULLTEXT INDEX](https://dev.mysql.com/doc/refman/8.0/en/innodb-fulltext-index.html){target="_blank"}). 

После установки и настройки всех необходимых индексов вы получите рабочий движок полнотекстового поиска. Однако, такой поиск будет лишён множества полезных функций: нечёткого поиска, поиска синонимов и стоп-слов, автодополнения, поддержки нескольких языков. 

Выбирая этот путь, мы немного улучшим поиск, но будем ограничены функциями, которые предоставляет БД. А что насчёт скорости? Оставив поиск «в руках» SQLite, вы не сможете сильно повлиять на её быстродействие. Значит, нужно рассмотреть возможности, предоставляемые другими БД с поддержкой полнотекстового поиска.  

## Проблемы производительности

Давайте присмотримся к PostgreSQL. Как повлияет на производительность смена СУБД?

- PostgreSQL — реляционная БД, из-за чего накладываются некоторые ограничения на производительность при большом количестве данных. PostgreSQL требует аккуратности, если количество данных превышает 1 ТБ в одной таблице. Также она требует вдумчивого создания индексов и умения оптимизировать запросы, 
чтобы получить наибольшую производительность.

- PostgreSQL плохо масштабируется на запись. Зачастую БД играет ключевую роль в сервисе, а это значит, что при падении базы данных перестанет работать и сам сервис. Имея всего один экземпляр БД, он становится уязвим к нагрузкам и сбоям. Чтобы избежать этой проблемы, используется масштабирование: запускается несколько копий БД, между которыми распределяются запросы. Так как обычно запросов на чтение поступает гораздо больше, чем на запись, их обработкой занимаются дополнительные копии, а {{основная}}[Всплывашка: При выходе из строя его роль берёт на себя одна из реплик.] отвечает за получение новых данных. Его принято называть `master`, а дополнительные — `slave`, хотя в последнее время набирают популярность термины `leader` и `follower`. У PostgreSQL нет элегантного решения для ситуаций, когда нагрузка на master становится слишком большой. Это приведёт к тому, что при сбое вы не сможете добавлять новые фильмы, хотя поиск будет работать. Реплики в этом случае не помогут, у вашего видеосервиса будет неприятный простой, а если такое падение произойдёт ночью, вы получите гарантированный недосып.

Увы, многие реляционные БД страдают примерно от тех же проблем, что и PostgreSQL. Поэтому если вы хотите сделать сервис, который будет выдерживать высокую нагрузку от пользователей, обладать гибкими настройками поиска по документам и сохранять при этом приемлемое время ответа, 
нужно использовать специализированные БД — {{поисковые движки}}[p2f_transtale_searchengine].

## Поисковые движки

Такие базы данных создавались специально, чтобы обрабатывать запросы по текстовым массивам. Среди них — Sphinx, Splunk, Solr, Elasticsearch, ArangoDB. Есть и другие БД для поиска, вы можете посмотреть их в [чарте](https://db-engines.com/en/ranking/search+engine){target="_blank"} (на английском). 

Для вашего онлайн-кинотеатра лучше использовать бесплатное решение с хорошей документацией. Если посмотреть на топ-5 баз данных, то под это описание подходит Elasticsearch, Solr и Sphinx. На них и остановимся:

- Sphinx — быстрый поисковый движок с {{SQL-like}}[p2f_python_sqllike] языком запросов. Очень прост в установке: нужно [скачать «бинарники»](http://www.sphinxsearch.com/downloads/current/){target="_blank"} и запустить. Нетребователен к настройкам. Также у Sphinx есть встроенная утилита перегрузки данных, которая умеет работать с PostgreSQL, MySQL и с любой БД, поддерживающей драйвер UnixODBC. Но установка этой утилиты требует выполнения определённого количества команд в консоли и большой аккуратности. Ещё один минус Sphinx — сложность установки кластерного решения.

- Solr — мощный поисковый движок, построенный с использованием Apache Lucene. У него есть те же функции, что и у Sphinx, но он сложен в установке, сопровождении и работе с API. Solr сильно заточен под Java, поэтому такое решение Python-разработчикам не подходит.

- Elasticsearch — самый популярный из трёх представленных поисковых движков. Он обладает всеми возможностями Solr, так как построен на базе Apache Lucene. При этом у него приятный в использовании [RESTful API](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html){target="_blank"}, который позволяет быстро делать запросы и проверять результат работы без особых проблем. Elasticsearch обладает ещё двумя преимуществами: полноценным полнотекстовым поиском, включая нечёткий поиск, и возможностями к горизонтальному масштабированию. Например, кластер Elasticsearch в «Одноклассниках» выдерживает [до 2–3 млн запросов в секунду](https://habr.com/ru/company/odnoklassniki/blog/494260/){target="_blank"} на запись. Из минусов: достаточно большое потребление ресурсов из-за Java Virtual Machine (JVM), относительно медленная запись данных, недостаток безопасности и частые поломки обратной совместимости {{при переходе между мажорными версиями}}[p2f_theme9_lesson2_python_changeversions].

Среди рассмотренных поисковых движков наиболее подходящим будет Elasticsearch. Продолжим работу над онлайн-кинотеатром с ним.

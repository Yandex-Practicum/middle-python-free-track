# Логика загрузки данных из SQLite в Elasticsearch

Теперь у вас есть все вводные, чтобы организовать перегрузку данных из SQLite в Elasticsearch. В этом уроке вы узнаете об общей архитектуре решения и подводных камнях, которые могут встретиться.

Начнём с архитектуры типового механизма перегрузки данных. Во многих статьях такой механизм называется ETL — Extract, Transform. Load. Разберём название на составляющие:

- `Extract` (получение данных) — модуль программы или системы, отвечающий за загрузку сырых данных из источника. В вашем случае это БД SQLite.
- `Transform` (преобразование/обогащение данных) — модуль программы или системы, изменяющий сырые данные из источника так, чтобы загрузить их в предназначенное для них место. Для вас этот этап опциональный. Он будет полезен, если вы придумаете, как очистить или преобразовать исходные данные для поиска.
- `Load` (загрузка в целевое хранилище) — модуль программы или системы, загружающий преобразованные данные в нужном формате в целевое хранилище. В вашем случае в роли целевого хранилища выступает Elasticsearch.

Изобразим схему, как механизм перегрузки будет вписываться в общую архитектуру:

![image](https://pictures.s3.yandex.net/resources/Skhema_1593632821.jpg)

Схема достаточно простая, но стоит сразу обозначить точки, где могут возникнуть проблемы:

**1. Запросы в SQLite**. 

Проблемы:

		- некорректные запросы;
		- слишком много параллельных запросов к одним и тем же данным;
		- медленное получение данных.

Механизмы лечения: 
	
		- тестировать запросы заранее;
		- сделать запросы следующими друг за другом;
		- в одном запросе стараться запрашивать небольшой фрагмент данных.

**2. Запросы в Elasticsearch (ES)**.

Проблемы:

		- некорректно составленные запросы;
		- дублирование данных;
		- скорость загрузки данных.

Механизмы лечения:

		- тестировать запросы заранее;
		- выбрать заранее набор полей, которые будут составлять `id` документов в ES;
		- загрузка одной записи одним HTTP-запросом происходит медленно,  поэтому нужно посмотреть в сторону загрузки `bulk`-запросами (т.е. отправлять за один запрос несколько записей).
		

**3. Сеть или падение одной из БД**.

Одна из основных проблем современных систем — ненадёжность сетевой инфраструктуры. Возникает множество трудностей со связностью систем и потерей сетевых пакетов. Всё это обязательно нужно учитывать в своих системах.

Другая, но не менее частая проблема —  выход дисков из строя. В один прекрасный момент любимая БД может накрыться медным тазом и заодно уложить все ваши ETL-процессы. Чтобы выжили хотя бы процессы, нужен механизм устойчивости к таким сбоям.

Проблемы:

		- потеря сетевого соединения с БД. Для SQLite этой проблемы нет, так как подключение идёт к файлу с БД;
		- побился файл БД SQLite;
		- упал ES.

Механизмы лечения:

		- в рамках ETL-процесса нужно заложить механизм повторов (retry-запросы) с увеличивающимся временем повторного запроса.

Обязательно закладывайте в системе увеличение времени между повторами, чтобы БД или сетевая инфраструктура после падения могла восстановить свою работоспособность.

**4. Падение «механизма загрузки данных»**.

Проблемы:

		- ошибка в коде;
		- падение вслед за БД или сетью.

Механизмы лечения:

		- покрывать код юнит- и интеграционными тестами;
		- внедрять механизмы устойчивости к падениям;
		- отслеживать, какие данные уже перегружены.

Основной упор в реализации механизма перегрузки данных необходимо сделать на способы восстановления работоспособности после падения. Чтобы решение получилось работающим, необходимо ответить на вопросы:

1. Как сделать так, чтобы при падении процесс перегрузки начал с того места, где завершил работу до падения?
2. Как не допустить дублей при загрузке данных в Elasticsearch?
3. Как слишком не нагружать запросами SQLite?
4. Как слишком не нагружать запросами Elasticsearch?